{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# urllib\n",
    "- 包含模块\n",
    "    - urllib.request：打开和读取urls\n",
    "    - urllib.error：包含urllib.request产生的常见的错误，使用try捕获\n",
    "    - urllib.parse：包含解析url的方法\n",
    "    - urllib.robotparse：解析robots.txt文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 网页编码问题解决\n",
    "    - chardet可以自动检测页面文件的编码格式，但是可能有误\n",
    "    - 需要安装：conda install chardet\n",
    "- urlopen\n",
    "    - 返回一个对象\n",
    "    - 对象的方法：\n",
    "        - geturl：返回请求对象的url\n",
    "        - info：请求反馈对象的meta信息\n",
    "        - getcode：返回http code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    url = \"地址\"\n",
    "    # 打开相应url并吧相应页面作为返回\n",
    "    rsp = request.urlopent(url)\n",
    "    \n",
    "    # 返回对象的方法\n",
    "    print(\"URL\",rsp.geturl())\n",
    "    print(\"meta\",rsp.info())\n",
    "    print(\"code\",rsp.getcode())\n",
    "    \n",
    "    # 把返回结果读取出来\n",
    "    # 读取的结果为bytes类型\n",
    "    \n",
    "    html = rsp.read()\n",
    "    \n",
    "    # 解码\n",
    "    html = html.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 请求参数\n",
    "    - 请求方式：get\n",
    "        - 利用参数给服务器传递信息\n",
    "        - 参数为dict，然后用parse编码\n",
    "    - 请求方式：post\n",
    "        - 一般向服务器传递参数使用\n",
    "        - 使用post信息，需要用到data参数\n",
    "        - 使用post，需要改变请求头\n",
    "            - Content-Type:application/x-www.form-urlencode\n",
    "            - Content-Length：数据长度\n",
    "        - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过get方式获取网页内容\n",
    "from urllib import request,parse\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = '地址'\n",
    "    wd = input(\"请输入你想要查询的内容\")\n",
    "    \n",
    "    #请求的参数\n",
    "    qs = {\n",
    "        \"wd\":wd\n",
    "    }\n",
    "    \n",
    "    # 将请求参数转换成url编码形式\n",
    "    qs = parse.urlencode(qs)\n",
    "    \n",
    "    # 完整的url地址\n",
    "    fullurl = url + qs\n",
    "    \n",
    "    # 获取页面内容\n",
    "    rsp = request.urlopen(fullurl)\n",
    "    \n",
    "    html = rsp.read()\n",
    "    \n",
    "    # 编码\n",
    "    html = html.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过post方式获取网页内容\n",
    "from urllib import request,parse\n",
    "import json\n",
    "\n",
    "# 地址\n",
    "baseurl = '地址'\n",
    "\n",
    "# 发送给服务器的参数\n",
    "data = {\n",
    "    'kw':'xx'\n",
    "}\n",
    "\n",
    "# 将参数编码\n",
    "data = parse.urlencode(data).encode(\"utf-8\")\n",
    "\n",
    "# 请求头\n",
    "headers = {\n",
    "    'Content-Length':len(data)\n",
    "}\n",
    "\n",
    "req = request.Request(url=baseurl, data=data, headers=headers)\n",
    "\n",
    "# 发送请求\n",
    "#rsp = request.urlopen(baseurl,data=data)\n",
    "\n",
    "rsp = request.urlopen(req)\n",
    "\n",
    "# 获取请求后的值\n",
    "json_data = rep.read().decode('utf-8')\n",
    "json_data = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 错误\n",
    "    - urlError，对应的一般为网络出现的问题：\n",
    "        - 没网\n",
    "        - 服务器连接失败\n",
    "        - 不知道指定服务器\n",
    "        - 是OSError的子类\n",
    "    - HTTPError，urlError的一个子类\n",
    "        - 是对应的HTTP请求的返回码错误，如果返回错误码是400以上，则引起HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request, error\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    url = \"http:iiiiiiiiidu//www.baidu.com/welcome.html\"\n",
    "\n",
    "    url = \"http://www.sipo.gov.cn/www\"\n",
    "    try:\n",
    "\n",
    "        req = request.Request(url)\n",
    "        rsp = request.urlopen( req )\n",
    "        html = rsp.read().decode()\n",
    "        print(html)\n",
    "\n",
    "    except error.HTTPError as e:\n",
    "        print(\"HTTPError: {0}\".format(e.reason))\n",
    "        print(\"HTTPError: {0}\".format(e))\n",
    "\n",
    "    except error.URLError as e:\n",
    "        print(\"URLError: {0}\".format(e.reason))\n",
    "        print(\"URLError: {0}\".format(e))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- UserAgent\n",
    "    - UserAgent：用户代理，属于头的一部分，服务器通过UA来判断访问者身份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "访问一个网址\n",
    "更改自己的UserAgent进行伪装\n",
    "'''\n",
    "from urllib import request, error\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    url = \"http://www.baidu.com\"\n",
    "\n",
    "\n",
    "    # 使用head方法伪装UA\n",
    "    # headers = {}\n",
    "    # headers['User-Agent'] = 'Mozilla/5.0 (iPad; CPU OS 5_0 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A334 Safari/7534.48.3'\n",
    "    # req = request.Request( url, headers=headers)\n",
    "\n",
    "    # 使用add_header方法\n",
    "    req = request.Request(url)\n",
    "    req.add_header(\"User-Agent\", \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.94 Safari/537.36\")\n",
    "\n",
    "    # 正常访问\n",
    "    rsp = request.urlopen( req )\n",
    "    html = rsp.read().decode()\n",
    "    print(html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ProxyHandler处理（代理服务器）\n",
    "    - 获取代理服务器地址\n",
    "        - www.xicidaili.com\n",
    "        - www.goubanjia.com\n",
    "    - 基本使用步骤：\n",
    "        - 设置代理地址 \n",
    "        - 创建ProxyHandler\n",
    "        - 创建Opener\n",
    "        - 安装Opener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import  request, error\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    url = \"http://www.baidu.com\"\n",
    "\n",
    "    # 使用代理步骤\n",
    "    # 1. 设置代理地址\n",
    "    proxy = {'http': '120.194.18.90:81' }\n",
    "    # 2. 创建ProxyHandler\n",
    "    proxy_handler = request.ProxyHandler(proxy)\n",
    "    # 3. 创建Opener\n",
    "    opener = request.build_opener(proxy_handler)\n",
    "    # 4. 安装Opener\n",
    "    request.install_opener( opener)\n",
    "\n",
    "    # 现在如果访问url，则使用代理服务器\n",
    "    try:\n",
    "        rsp = request.urlopen(url)\n",
    "        html = rsp.read().decode()\n",
    "        print(html)\n",
    "    except error.URLError as e:\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用cookie登录\n",
    "    - 1、直接把cookie复制下来，然后手动放入请求头\n",
    "    - 2、http模块包含一些关于cookie的模块，可以自动使用cookie\n",
    "        - CookieJar：管理存储cookie，向传出的http请求添加cookie\n",
    "            - cookie存储在内存中，cookieJar实例回收后cookie将消失\n",
    "        - FileCookieJar(filename,delayload=None,policy=None)\n",
    "            - 使用文件管理cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request,parse\n",
    "from http import cookiejar\n",
    "\n",
    "# 创建cookiejar的实例\n",
    "cookie = cookiejar.CookieJar()\n",
    "\n",
    "# 生成cookie的管理器\n",
    "cookie_handler = request.HTTPCookieProcessor(cookie)\n",
    "\n",
    "# 创建http请求管理器\n",
    "http_handler = request.HTTPHandler()\n",
    "\n",
    "# 生成https管理器\n",
    "https_handler = request.HTTPHandler()\n",
    "\n",
    "# 创建请求管理器\n",
    "opener = request.build_opener(http_handler,https_handler,cookie_handler)\n",
    "\n",
    "def login():\n",
    "    '''\n",
    "    负责初次登录\n",
    "    需要输入用户名密码，用来获取登录cookie凭证\n",
    "    '''\n",
    "    \n",
    "    # 请求地址\n",
    "    url = \"xxxx\"\n",
    "    \n",
    "    # 此键值需要从登录form的两个对应input中提取name属性\n",
    "    data = {\n",
    "        \"email\":\"xxx\",\n",
    "        \"passwd\":\"sad\"\n",
    "    }\n",
    "    \n",
    "    # 数据编码\n",
    "    data = parse.urlencode(data)\n",
    "    \n",
    "    # 创建一个请求对象\n",
    "    req = request.Request(url,data=data.encode())\n",
    "    \n",
    "    # 使用opener发起请求\n",
    "    rsp = opener.open(req)\n",
    "    \n",
    "def getHomePage():\n",
    "    url = \"xxx\"\n",
    "    \n",
    "    # 如果已经执行了login函数，则opener自动已经包含cookie值\n",
    "    rsp = opener.open(url)\n",
    "    \n",
    "    html = rsp.read().decode()\n",
    "    \n",
    "    with open(\"rsp.html\",\"w\") as f:\n",
    "        f.write(html)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    login()\n",
    "    getHomePage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SSL\n",
    "    - SSL证书就是指遵循SSL安全套阶层协议的服务器数字证书\n",
    "    - CA：数字证书认证中心，是发放、管理、废除数字证书的收信人的第三方机构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "# 导入pythopn ssl处理模块\n",
    "import ssl\n",
    "\n",
    "# 利用非认证上下文环境替换认证的向下文环境\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "url = \"https://www.12306.cn/mormhweb/\"\n",
    "rsp = request.urlopen(url)\n",
    "\n",
    "html = rsp.read().decode()\n",
    "\n",
    "print(html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
