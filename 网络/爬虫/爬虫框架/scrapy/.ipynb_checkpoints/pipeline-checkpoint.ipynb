{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item pipeline\n",
    "- 项目管道，当item生成后，会自动送到item pipeline进行处理\n",
    "- 常用操作\n",
    "    - 清理HTML数据\n",
    "    - 验证爬取数据，检查爬取字段\n",
    "    - 查重并丢弃重复内容\n",
    "    - 将爬取结果保存到数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现方法\n",
    "- 定义一个类并实现 process_item()\n",
    "- 启用item pipeline后，会自动调用这个方法\n",
    "- 该方法必须返回包含数据的字典或item对象或抛出dropitem异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pipelines.py文件中：对数据的处理\n",
    "'''\n",
    "from scrapy.exceptions import DropItem\n",
    "\n",
    "class TextPipeline(object):\n",
    "    def __init__(self):\n",
    "        self.limit = 50\n",
    "    \n",
    "    def process_item(self,item,spider):\n",
    "        if item['text']:\n",
    "            if len(item['text']) > self.limit:\n",
    "                item['text'] = item['text'][0:self.limit].rstrip() + '...'\n",
    "            return item\n",
    "        else:\n",
    "            return DropItem('Missing Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pipelines.py文件中：存储到mongodb数据库中\n",
    "'''\n",
    "import pymongo\n",
    "class MongoPipeline(object):\n",
    "    def __init__(self,mongo_uri,mongo_db):\n",
    "        self.mongo_uri = mongo_url\n",
    "        self.mongo_db = mongo_db\n",
    "    \n",
    "    @classmethod\n",
    "    '''\n",
    "    类方法：通过crawler可以拿到全局配置的每个配置信息，即settings.py中的配置内容\n",
    "    '''\n",
    "    def form_crawler(cls,crawler):\n",
    "        return cls(\n",
    "            mongo_uri = crawler.settings.get('MONGO_URI'),\n",
    "            mongo_db = crawler.setting.get('MONGO_DB')\n",
    "        )\n",
    "    '''\n",
    "    当spider开启时，会被调用\n",
    "    '''\n",
    "    def open_spider(self,spider):\n",
    "        self.client = pymongo.MongoClient(self.mongo_uri)\n",
    "        self.db = self.client[self.mongo_db]\n",
    "    '''\n",
    "    数据的插入\n",
    "    '''\n",
    "    def process_item(self,item,spider):\n",
    "        name = item.__class__.__name__\n",
    "        self.db[name].insert(dict(item))\n",
    "        return item\n",
    "\n",
    "    '''\n",
    "    当spider关闭时，调用该方法\n",
    "    '''\n",
    "    def close_spider(self,spider):\n",
    "        self.client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
